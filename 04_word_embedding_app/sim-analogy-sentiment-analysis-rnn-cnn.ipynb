{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Pre-trained Word Embeddings\n",
    "\n",
    "This notebook will demonstrate how to use pre-trained word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To see why word embeddings are useful, it's worth comparing them to the alternative.\n",
    "Without word embeddings, we might represent each word with a one-hot vector `[0, ...,0, 1, 0, ... 0]`, that takes value `1` at the index corresponding to the appropriate vocabulary word, \n",
    "and value `0` everywhere else. \n",
    "The weight matrices connecting our word-level inputs to the network's hidden layers would each be $v \\times h$,\n",
    "where $v$ is the size of the vocabulary and $h$ is the size of the hidden layer. \n",
    "With 100,000 words feeding into an LSTM layer with $1000$ nodes, the model would need to learn\n",
    "$4$ different weight matrices (one for each of the LSTM gates), each with 100M weights, and thus 400 million parameters in total.\n",
    "\n",
    "Fortunately, it turns out that a number of efficient techniques \n",
    "can quickly discover broadly useful word embeddings in an *unsupervised* manner.\n",
    "These embeddings map each word onto a low-dimensional vector $w \\in R^d$ with $d$ commonly chosen to be roughly $100$.\n",
    "Intuitively, these embeddings are chosen based on the contexts in which words appear. \n",
    "Words that appear in similar contexts (like \"tennis\" and \"racquet\") should have similar embeddings\n",
    "while words that do not like (like \"rat\" and \"gourmet\") should have dissimilar embeddings.\n",
    "\n",
    "Practitioners of deep learning for NLP typically inititalize their models \n",
    "using *pretrained* word embeddings, bringing in outside information, and reducing the number of parameters that a neural network needs to learn from scratch.\n",
    "\n",
    "\n",
    "Two popular word embeddings are Word2Vec and fastText. \n",
    "The following examples uses pre-trained word embeddings drawn from the following sources:\n",
    "\n",
    "* Word2Vec https://arxiv.org/abs/1301.3781\n",
    "* fastText project websiteï¼šhttps://fasttext.cc/\n",
    "\n",
    "To begin, let's first import a few packages that we'll need for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:55:57.268321Z",
     "start_time": "2019-08-06T00:55:55.896925Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon import rnn, nn\n",
    "import gluonnlp as nlp\n",
    "import re\n",
    "import d2l\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "GluonNLP provides a number of pre-trained Word Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:55:57.276247Z",
     "start_time": "2019-08-06T00:55:57.270436Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crawl-300d-2M', 'crawl-300d-2M-subword', 'wiki.aa', 'wiki.ab', 'wiki.ace']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.embedding.list_sources('fasttext')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For simplicity of demonstration, we use a smaller word embedding file, such as\n",
    "the 50-dimensional one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:32.875568Z",
     "start_time": "2019-08-06T00:55:57.278291Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "emb = nlp.embedding.create('fasttext', source='wiki.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Given an input word, we can find the nearest word from\n",
    "the vocabulary by similarity. The\n",
    "similarity between any pair of words can be represented by the cosine similarity\n",
    "of their vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:32.887896Z",
     "start_time": "2019-08-06T00:56:32.877797Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def norm_vecs_by_row(x):\n",
    "    return x / nd.sqrt(nd.sum(x * x, axis=1) + 1E-10).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:32.893025Z",
     "start_time": "2019-08-06T00:56:32.889039Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_knn(emb, k, word):\n",
    "    word_vec = emb[word].reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(emb.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs, word_vec)\n",
    "    indices = nd.topk(dot_prod.reshape((len(emb.idx_to_token), )), k=k+1, ret_typ='indices')\n",
    "    indices = [int(i.asscalar()) for i in indices]\n",
    "    return [emb.idx_to_token[i] for i in indices[1:]] # Remove input tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us find the 2 most similar words of 'baby' from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:44.063121Z",
     "start_time": "2019-08-06T00:56:32.894245Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['babies', 'newborn']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(emb, 2, 'baby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can verify the cosine similarity of vectors of 'baby' and 'babies'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:44.071293Z",
     "start_time": "2019-08-06T00:56:44.065048Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.76009405]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "def cos_sim(x, y):\n",
    "    return nd.dot(x, y) / (nd.norm(x) * nd.norm(y))\n",
    "\n",
    "cos_sim(emb['baby'], emb['babies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can also apply pre-trained word embeddings to the word\n",
    "analogy problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "For instance, \"man : woman :: son : daughter\" is an analogy.\n",
    "\n",
    "![](../img/analogy.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The word analogy completion problem is defined as: for analogy 'a : b :: c : d',\n",
    "given the first three words 'a', 'b', 'c', find 'd'. The idea is to find the\n",
    "most similar word vector for vec('c') + (vec('b')-vec('a')).\n",
    "\n",
    "In this example, we will find words by analogy from the 400,000 indexed words in `vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:44.078688Z",
     "start_time": "2019-08-06T00:56:44.073290Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_k_by_analogy(emb, k, word1, word2, word3):\n",
    "    word_vecs = emb[word1, word2, word3]\n",
    "    word_diff = (word_vecs[1] - word_vecs[0] + word_vecs[2]).reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(emb.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs, word_diff)\n",
    "    indices = nd.topk(dot_prod.reshape((len(emb.idx_to_token), )), k=k, ret_typ='indices')\n",
    "    indices = [int(i.asscalar()) for i in indices]\n",
    "    return [emb.idx_to_token[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Complete word analogy 'man : woman :: son :'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:52.843603Z",
     "start_time": "2019-08-06T00:56:44.081174Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daughter']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(emb, 1, 'man', 'woman', 'son')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Classification and Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Text classification is a common task in natural language processing, which transforms a sequence of text of indefinite length into a category of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Text Sentiment Classification Data\n",
    "\n",
    "Use Stanford's Large Movie Review Dataset as the data set for text sentiment classification.\n",
    "- Contains parts for training and testing purposes, each containing 25,000 movie reviews downloaded from IMDb\n",
    "- In each data set, the number of comments labeled as \"positive\" and \"negative\" is equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset in `gluon`\n",
    "\n",
    "Datasets in Gluon have the following basic structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "``` python\n",
    "class Dataset(object):\n",
    "    def __getitem__(self, idx):\n",
    "        ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        ...\n",
    "\n",
    "    def transform(self, fn, lazy=True):\n",
    "        # Returns a new dataset with each sample\n",
    "        # transformed by the function `fn`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can make list-like Python object (ie. that implements `__getitem__` meaning it  subscripted like `x[0]` etc.),\n",
    "into a `gluon` `Dataset` by wrapping it, using `gluon.data.SimpleDataset` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:54.353169Z",
     "start_time": "2019-08-06T00:56:52.844608Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_while_preserving_label(sample):\n",
    "    sentence, label = sample\n",
    "    return sentence.split(), label\n",
    "\n",
    "train_dataset, test_dataset = [nlp.data.IMDB(segment=segment).transform(\n",
    "    tokenize_while_preserving_label, lazy=False)\n",
    "    for segment in ('train', 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:54.356637Z",
     "start_time": "2019-08-06T00:56:54.354237Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy.', 'It', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life,', 'such', 'as', '\"Teachers\".', 'My', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'Bromwell', \"High's\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"Teachers\".', 'The', 'scramble', 'to', 'survive', 'financially,', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', \"teachers'\", 'pomp,', 'the', 'pettiness', 'of', 'the', 'whole', 'situation,', 'all', 'remind', 'me', 'of', 'the', 'schools', 'I', 'knew', 'and', 'their', 'students.', 'When', 'I', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school,', 'I', 'immediately', 'recalled', '.........', 'at', '..........', 'High.', 'A', 'classic', 'line:', 'INSPECTOR:', \"I'm\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers.', 'STUDENT:', 'Welcome', 'to', 'Bromwell', 'High.', 'I', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'Bromwell', 'High', 'is', 'far', 'fetched.', 'What', 'a', 'pity', 'that', 'it', \"isn't!\"], 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:55.756052Z",
     "start_time": "2019-08-06T00:56:54.358194Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=28740, unk=\"<unk>\", reserved=\"['<pad>', '<bos>', '<eos>']\")\n",
      "['<unk>', '<pad>', '<bos>', '<eos>', 'the', 'a', 'and', 'of', 'to', 'is', '...']\n"
     ]
    }
   ],
   "source": [
    "def get_text(text, label):\n",
    "    return text\n",
    "train_tokens = train_dataset.transform(get_text)\n",
    "\n",
    "import itertools\n",
    "vocab = nlp.Vocab(nlp.data.count_tokens(itertools.chain.from_iterable(train_tokens)), min_freq=10)\n",
    "print(vocab)\n",
    "print(vocab.idx_to_token[:10] + [\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:55.763893Z",
     "start_time": "2019-08-06T00:56:55.758113Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2720, 9, 5, 1400, 1352, 58, 2225, 33, 4, 171, 85, 17, 48, 82, 9137, 44, 520, 778, 140, 17, 0, 361, 7185, 193, 10, 4, 5819, 8968, 495, 86, 8, 265, 12, 0, 0, 2638, 9, 80, 2646, 8, 899, 72, 9, 0, 21, 0, 8, 2718, 0, 4, 7999, 1898, 37, 66, 69, 259, 150, 57, 1710, 0, 0, 4, 0, 7, 4, 215, 5442, 39, 2989, 86, 7, 4, 8660, 11, 638, 6, 57, 9156, 285, 11, 209, 4, 484, 10, 64, 5, 1839, 4580, 765, 8, 4401, 217, 4, 3156, 11, 1371, 19648, 0, 33, 0, 27132, 135, 443, 7613, 0, 162, 227, 8, 14323, 34, 7, 119, 0, 0, 18376, 8, 0, 27132, 11, 546, 12, 104, 2044, 7, 68, 879, 100, 12, 0, 2720, 9, 239, 0, 257, 5, 3155, 12, 14, 0], 1]\n"
     ]
    }
   ],
   "source": [
    "# `length_clip` takes as input a list and outputs a list with maximum length 500.\n",
    "length_clip = nlp.data.ClipSequence(500)\n",
    "\n",
    "def preprocess(data, label):\n",
    "    label = int(label > 5)\n",
    "    data = vocab[length_clip(data)]\n",
    "    return [data, label]\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.transform(preprocess)\n",
    "test_dataset = test_dataset.transform(preprocess)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `gluonnlp.data.batchify.Pad`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`gluonnlp.data.batchify.Pad` can be instantiated with the padding value.\n",
    "The resulting function takes a list of variable length lists (or NDArrays or numpy arrays)\n",
    "as input and returns a single NDArray where all shorter inputs are padded to the length\n",
    "of the maximum length input element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:55.769863Z",
     "start_time": "2019-08-06T00:56:55.765875Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 428\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset[0][0]), len(train_dataset[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:55.775161Z",
     "start_time": "2019-08-06T00:56:55.771336Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_val: 1\n"
     ]
    }
   ],
   "source": [
    "# Pad data, stack label and lengths\n",
    "pad_val = vocab[vocab.padding_token]\n",
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(axis=0, ret_length=True, pad_val=pad_val),\n",
    "    nlp.data.batchify.Stack(dtype='float32'))\n",
    "print('pad_val:', pad_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:55.781501Z",
     "start_time": "2019-08-06T00:56:55.776487Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((\n",
       "  [[0.0000e+00 2.7200e+03 9.0000e+00 ... 1.0000e+00 1.0000e+00 1.0000e+00]\n",
       "   [0.0000e+00 9.0800e+02 0.0000e+00 ... 8.0000e+00 3.3700e+02 2.2630e+03]\n",
       "   [1.1217e+04 1.7181e+04 3.2000e+01 ... 1.0000e+00 1.0000e+00 1.0000e+00]]\n",
       "  <NDArray 3x428 @cpu_shared(0)>, \n",
       "  [140 428 147]\n",
       "  <NDArray 3 @cpu_shared(0)>), \n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu_shared(0)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchify_fn([train_dataset[0], train_dataset[1], train_dataset[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `gluon.data.DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Manually sampling sentences from the dataset and applying the pad function may be bothersome.\n",
    "`gluon.data.DataLoader` automates this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:55.785082Z",
     "start_time": "2019-08-06T00:56:55.782595Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads data from a dataset and returns mini-batches of data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset : Dataset\n",
      "        Source dataset. Note that numpy and mxnet arrays can be directly used\n",
      "        as a Dataset.\n",
      "    batch_size : int\n",
      "        Size of mini-batch.\n",
      "    shuffle : bool\n",
      "        Whether to shuffle the samples.\n",
      "    sampler : Sampler\n",
      "        The sampler to use. Either specify sampler or shuffle, not both.\n",
      "    last_batch : {'keep', 'discard', 'rollover'}\n",
      "        How to handle the last batch if batch_size does not evenly divide\n",
      "        `len(dataset)`.\n",
      "\n",
      "        keep - A batch with less samples than previous batches is returned.\n",
      "        discard - The last batch is discarded if its incomplete.\n",
      "        rollover - The remaining samples are rolled over to the next epoch.\n",
      "    batch_sampler : Sampler\n",
      "        A sampler that returns mini-batches. Do not specify batch_size,\n",
      "        shuffle, sampler, and last_batch if batch_sampler is specified.\n",
      "    batchify_fn : callable\n",
      "        Callback function to allow users to specify how to merge samples\n",
      "        into a batch. Defaults to `default_batchify_fn`::\n",
      "\n",
      "            def default_batchify_fn(data):\n",
      "                if isinstance(data[0], nd.NDArray):\n",
      "                    return nd.stack(*data)\n",
      "                elif isinstance(data[0], tuple):\n",
      "                    data = zip(*data)\n",
      "                    return [default_batchify_fn(i) for i in data]\n",
      "                else:\n",
      "                    data = np.asarray(data)\n",
      "                    return nd.array(data, dtype=data.dtype)\n",
      "\n",
      "    num_workers : int, default 0\n",
      "        The number of multiprocessing workers to use for data preprocessing.\n",
      "    pin_memory : boolean, default False\n",
      "        If ``True``, the dataloader will copy NDArrays into pinned memory\n",
      "        before returning them. Copying from CPU pinned memory to GPU is faster\n",
      "        than from normal CPU memory.\n",
      "    pin_device_id : int, default 0\n",
      "        The device id to use for allocating pinned memory if pin_memory is ``True``\n",
      "    prefetch : int, default is `num_workers * 2`\n",
      "        The number of prefetching batches only works if `num_workers` > 0.\n",
      "        If `prefetch` > 0, it allow worker process to prefetch certain batches before\n",
      "        acquiring data from iterators.\n",
      "        Note that using large prefetching batch will provide smoother bootstrapping performance,\n",
      "        but will consume more shared_memory. Using smaller number may forfeit the purpose of using\n",
      "        multiple worker processes, try reduce `num_workers` in this case.\n",
      "        By default it defaults to `num_workers * 2`.\n",
      "    thread_pool : bool, default False\n",
      "        If ``True``, use threading pool instead of multiprocessing pool. Using threadpool\n",
      "        can avoid shared memory usage. If `DataLoader` is more IO bounded or GIL is not a killing\n",
      "        problem, threadpool version may achieve better performance than multiprocessing.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(gluon.data.DataLoader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:58.043772Z",
     "start_time": "2019-08-06T00:56:55.786536Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of batches is 500.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "data_loader = gluon.data.DataLoader(train_dataset, batchify_fn=batchify_fn,\n",
    "                                    batch_size=batch_size)\n",
    "print('Average length of batches is', sum(batch[0][0].shape[1] for batch in data_loader) / len(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:37:20.742611Z",
     "start_time": "2018-08-20T20:37:20.738625Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../img/fixed_bucket_strategy_ratio0.7.png\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Custom `Sampler` for `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Sampling random sentences from the Dataset and padding them is sub-optimal as the number of padding elments is determined by the longest sentence.\n",
    "`DataLoader` supports the specification of a `Sampler` to specify the sentences to select for a batch.\n",
    "\n",
    "For example, `gluonnlp.data.FixedBucketSampler` assigns each data sample (sentence)\n",
    "to a fixed bucket based on its length. Resulting batches will only contain sentences\n",
    "from a single bucket.\n",
    "\n",
    "This can significantly reduce the average number of elements per batch and consequently the amount of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:56:58.047832Z",
     "start_time": "2019-08-06T00:56:58.045167Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign each data sample to a fixed bucket based on its length.\n",
      "    The bucket keys are either given or generated from the input sequence lengths.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    lengths : list of int or list of tuple/list of int\n",
      "        The length of the sequences in the input data sample.\n",
      "    batch_size : int\n",
      "        The batch size of the sampler.\n",
      "    num_buckets : int or None, default 10\n",
      "        The number of buckets. This will not be used if bucket_keys is set.\n",
      "    bucket_keys : None or list of int or list of tuple, default None\n",
      "        The keys that will be used to create the buckets. It should usually be the lengths of the\n",
      "        sequences. If it is None, the bucket_keys will be generated based on the maximum\n",
      "        lengths of the data.\n",
      "    ratio : float, default 0\n",
      "        Ratio to scale up the batch size of smaller buckets.\n",
      "        Assume the :math:`i` th key is :math:`K_i` ,\n",
      "        the default batch size is :math:`B` , the ratio to scale the batch size is\n",
      "        :math:`\\alpha` and\n",
      "        the batch size corresponds to the :math:`i` th bucket is :math:`B_i` . We have:\n",
      "\n",
      "        .. math::\n",
      "\n",
      "            B_i = \\max(\\alpha B \\times \\frac{\\max_j sum(K_j)}{sum(K_i)}, B)\n",
      "\n",
      "        Thus, setting this to a value larger than 0, like 0.5, will scale up the batch size of the\n",
      "        smaller buckets.\n",
      "    shuffle : bool, default False\n",
      "        Whether to shuffle the batches.\n",
      "    use_average_length : bool, default False\n",
      "        False: each batch contains batch_size sequences, number of sequence elements varies.\n",
      "        True: each batch contains batch_size elements, number of sequences varies. In this case,\n",
      "        ratio option is ignored.\n",
      "    num_shards : int, default 0\n",
      "        If num_shards > 0, the sampled batch is split into num_shards smaller batches.\n",
      "        The output will have structure of list(list(int)).\n",
      "        If num_shards = 0, the output will have structure of list(int).\n",
      "        This is useful in multi-gpu training and can potentially reduce the number of paddings.\n",
      "        In general, it is set to the number of gpus.\n",
      "    bucket_scheme : BucketScheme, default ConstWidthBucket\n",
      "        It is used to generate bucket keys. It supports:\n",
      "        ConstWidthBucket: all the buckets have the same width\n",
      "        LinearWidthBucket: the width of ith  bucket follows :math:`w_i = \\alpha * i + 1`\n",
      "        ExpWidthBucket: the width of ith bucket follows\n",
      "        :math:`w_i` = bucket_len_step :math:`* w_{i-1}`\n",
      "    Examples\n",
      "    --------\n",
      "    >>> lengths = [np.random.randint(1, 100) for _ in range(1000)]\n",
      "    >>> sampler = gluonnlp.data.FixedBucketSampler(lengths, 8, ratio=0.5)\n",
      "    >>> print(sampler.stats())\n",
      "    FixedBucketSampler:\n",
      "    -etc-\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nlp.data.FixedBucketSampler.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:01.311577Z",
     "start_time": "2019-08-06T00:56:58.049761Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=25000, batch_num=201\n",
      "  key=[59, 108, 157, 206, 255, 304, 353, 402, 451, 500]\n",
      "  cnt=[1036, 2543, 7173, 4296, 2619, 1729, 1330, 954, 733, 2587]\n",
      "  batch_size=[128, 128, 128, 128, 128, 128, 128, 128, 128, 128]\n"
     ]
    }
   ],
   "source": [
    "train_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=train_dataset.transform(lambda x: len(x[0]), lazy=False),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=test_dataset.transform(lambda x: len(x[0]), lazy=False),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(train_sampler.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.514465Z",
     "start_time": "2019-08-06T00:57:01.312652Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of batches is 241.4228855721393\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = gluon.data.DataLoader(train_dataset, batchify_fn=batchify_fn, batch_sampler=train_sampler)\n",
    "test_dataloader = gluon.data.DataLoader(test_dataset, batchify_fn=batchify_fn, batch_sampler=test_sampler)\n",
    "print('Average length of batches is',\n",
    "      sum(batch[0][0].shape[1] for batch in train_dataloader) / len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.532796Z",
     "start_time": "2019-08-06T00:57:03.516422Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((\n",
       "  [[2.100e+01 2.600e+01 3.071e+03 ... 4.970e+02 7.570e+02 1.000e+00]\n",
       "   [1.580e+02 6.700e+01 5.500e+01 ... 1.000e+00 1.000e+00 1.000e+00]\n",
       "   [2.100e+01 2.600e+01 3.559e+03 ... 1.000e+00 1.000e+00 1.000e+00]\n",
       "   ...\n",
       "   [1.162e+03 1.120e+03 3.500e+01 ... 3.900e+01 3.020e+02 1.000e+00]\n",
       "   [1.100e+01 4.300e+01 1.880e+02 ... 1.000e+00 1.000e+00 1.000e+00]\n",
       "   [1.350e+02 7.404e+03 0.000e+00 ... 1.000e+00 1.000e+00 1.000e+00]]\n",
       "  <NDArray 128x108 @cpu_shared(0)>, \n",
       "  [107  91  85  92  69  90  99 107  90 106 105  89  62 103  86 100  60  67\n",
       "    80  77  62  60 102  62  80  95  94  67  83  75 105 101  67  67  64 105\n",
       "    99  95  78 106 107 107 105  70  83  88  95 102  61  85 105  99  69  63\n",
       "    87  97  86  92  83  86  78  75 104  77  87 103 103 104  64  61 108  85\n",
       "    75  99  69 108 101 101  86 103  77  98  73  88  96  98  69  76  78 106\n",
       "    95 107  85  80 102  63  76  80 108  87  97 103  99  74 103 107  95  82\n",
       "    61  69  88 102  88  63  65  92  92  63  80  96  90  71  79  88  75 107\n",
       "    84  60]\n",
       "  <NDArray 128 @cpu_shared(0)>), \n",
       " [1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
       "  0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
       "  1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
       "  0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1.\n",
       "  1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
       "  0. 1. 0. 1. 0. 1. 1. 0.]\n",
       " <NDArray 128 @cpu_shared(0)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification Models: Using a Bag of Context Free Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Train and Evaluate the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.539799Z",
     "start_time": "2019-08-06T00:57:03.536059Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, ctx, net):\n",
    "    accuracy = 0\n",
    "    ctx = d2l.try_gpu()\n",
    "    for i, ((inputs, _), labels) in enumerate(test_data):\n",
    "        inputs = inputs.as_in_context(ctx)\n",
    "        labels = labels.as_in_context(ctx)\n",
    "        outs = net(inputs)\n",
    "        accuracy += (outs.argmax(axis=1).squeeze() == labels).mean()\n",
    "    print(\"Test Acc {}\".format(accuracy.asscalar()/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.551542Z",
     "start_time": "2019-08-06T00:57:03.541978Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, loss, trainer, num_epochs, ctx):\n",
    "    num_batches = len(train_iter)\n",
    "    params = [p for p in net.collect_params().values() if p.grad_req != 'null']\n",
    "    for epoch in range(num_epochs):\n",
    "        accuracy = mx.metric.Accuracy()\n",
    "        running_loss = 0\n",
    "        for i, ((features, _), labels) in enumerate(train_iter):           \n",
    "            features = gluon.utils.split_and_load(features, ctx, even_split=False)\n",
    "            labels = gluon.utils.split_and_load(labels, ctx, even_split=False)\n",
    "            losses, preds = [], []\n",
    "            with mx.autograd.record():\n",
    "                for feature, label in zip(features, labels):\n",
    "                    y = net(feature)\n",
    "                    l = loss(y, label)\n",
    "                    losses.append(l)\n",
    "                    preds.append(y)\n",
    "            mx.autograd.backward(losses)\n",
    "            for l in losses:\n",
    "                running_loss += l.mean().asscalar() / len(losses)\n",
    "            # Gradient clipping\n",
    "            trainer.allreduce_grads()\n",
    "            nlp.utils.clip_grad_global_norm(params, 1)\n",
    "            trainer.update(1)\n",
    "            accuracy.update(labels, preds)\n",
    "            if i % 25 == 0:\n",
    "                print(\"Batch\", i, \"Acc\", accuracy.get()[1],\"Train Loss\", running_loss/(i+1))\n",
    "        print(\"Epoch {}, Acc {}, Train Loss {}\".format(epoch, accuracy.get(), running_loss/(i+1)))\n",
    "        evaluate(test_iter, ctx, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We define a prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.557268Z",
     "start_time": "2019-08-06T00:57:03.553507Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "49"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    sentence = nd.array(vocab[sentence.split()], ctx=d2l.try_gpu())\n",
    "    label = nd.argmax(net(sentence.reshape((1, -1))), axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Recurrent Neural Networks\n",
    "\n",
    "In this section, we will apply\n",
    "pre-trained word vectors and bidirectional recurrent neural networks with\n",
    "multiple hidden layers:\n",
    "\n",
    "Maas, Andrew L., et al. \"Learning word vectors for sentiment analysis.\" Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies-volume 1. Association for Computational Linguistics, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bidirectional RNNs\n",
    "\n",
    "![BiRNN](../img/birnn.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Use a Recurrent Neural Network Model\n",
    "\n",
    "In this model, each word first obtains a feature vector from the embedding\n",
    "layer. Then, we further encode the feature sequence using a bidirectional\n",
    "recurrent neural network to obtain sequence information. Finally, we transform\n",
    "the encoded sequence information to output through the fully connected\n",
    "layer. Specifically, we can concatenate hidden states of bidirectional\n",
    "long-short term memory in the initial time step and final time step and pass it\n",
    "to the output layer classification as encoded feature sequence information. In\n",
    "the `BiRNN` class implemented below, the `Embedding` instance is the embedding\n",
    "layer, the `LSTM` instance is the hidden layer for sequence encoding, and the\n",
    "`Dense` instance is the output layer for generated classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.564767Z",
     "start_time": "2019-08-06T00:57:03.559202Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "46"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = rnn.LSTM(num_hiddens, num_layers=num_layers,\n",
    "                                bidirectional=True, input_size=embed_size)\n",
    "        self.decoder = nn.Dense(2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(mx.nd.transpose(inputs))\n",
    "        outputs = self.encoder(embeddings)\n",
    "        encoding = mx.nd.concat(outputs[0], outputs[-1])\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create a bidirectional recurrent neural network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:57:03.576267Z",
     "start_time": "2019-08-06T00:57:03.566167Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ctx, embed_size = d2l.try_all_gpus(), 300\n",
    "num_hiddens, num_layers = 100, 2\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:08:46.265089Z",
     "start_time": "2019-08-06T00:57:03.578697Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28740, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = nlp.embedding.create('fasttext', source='wiki.simple', load_ngrams=True)\n",
    "idx_to_vec = emb[vocab.idx_to_token]\n",
    "idx_to_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Load Pre-trained Word Vectors\n",
    "\n",
    "Because the training data set for sentiment classification is not very large, in order to deal with overfitting, we will directly use word vectors pre-trained on a larger corpus as the feature vectors of all words. Here, we load a 100-dimensional GloVe word vector for each word in the dictionary `vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:08:46.270877Z",
     "start_time": "2019-08-06T01:08:46.267591Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "47"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(idx_to_vec)\n",
    "net.embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "Now, we can start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.295788Z",
     "start_time": "2019-08-06T01:08:46.275569Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "48"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Acc 0.4296875 Train Loss 0.6971674263477325\n",
      "Batch 25 Acc 0.5017257609036712 Train Loss 0.6940228577989799\n",
      "Batch 50 Acc 0.5381685446754484 Train Loss 0.6845305223090976\n",
      "Batch 75 Acc 0.5690979896852962 Train Loss 0.6740727840285552\n",
      "Batch 100 Acc 0.5963998105163429 Train Loss 0.6611765727105707\n",
      "Batch 125 Acc 0.6175413832926986 Train Loss 0.6445062925654744\n",
      "Batch 150 Acc 0.6287134002992092 Train Loss 0.640028860740709\n",
      "Batch 175 Acc 0.6359174311926605 Train Loss 0.638100395063785\n",
      "Batch 200 Acc 0.649 Train Loss 0.6258232837440956\n",
      "Epoch 0, Acc ('accuracy', 0.649), Train Loss 0.6258232837440956\n",
      "Test Acc 0.7428757557317839\n",
      "Batch 0 Acc 0.7421875 Train Loss 0.5544990450143814\n",
      "Batch 25 Acc 0.7036923076923077 Train Loss 0.5885903798043728\n",
      "Batch 50 Acc 0.7211448232718173 Train Loss 0.5676899084857866\n",
      "Batch 75 Acc 0.7192107775538348 Train Loss 0.5787880223636565\n",
      "Batch 100 Acc 0.7357649120012741 Train Loss 0.5558922559317976\n",
      "Batch 125 Acc 0.7340229739163546 Train Loss 0.5557242399525075\n",
      "Batch 150 Acc 0.7387377815554611 Train Loss 0.5532608849940118\n",
      "Batch 175 Acc 0.7410550458715597 Train Loss 0.5508623398438265\n",
      "Batch 200 Acc 0.74376 Train Loss 0.5467833197254002\n",
      "Epoch 1, Acc ('accuracy', 0.74376), Train Loss 0.5467833197254002\n",
      "Test Acc 0.7735101901107098\n",
      "Batch 0 Acc 0.734375 Train Loss 0.5503932312130928\n",
      "Batch 25 Acc 0.7736612702366127 Train Loss 0.49301312763530475\n",
      "Batch 50 Acc 0.7721050088581092 Train Loss 0.4966007251219422\n",
      "Batch 75 Acc 0.7718142204272505 Train Loss 0.5024928976046411\n",
      "Batch 100 Acc 0.7687080268628078 Train Loss 0.5133650274117394\n",
      "Batch 125 Acc 0.7655966865130728 Train Loss 0.519402031919786\n",
      "Batch 150 Acc 0.7667829353367319 Train Loss 0.5178056672610194\n",
      "Batch 175 Acc 0.7673460041218227 Train Loss 0.5151040753857656\n",
      "Batch 200 Acc 0.75984 Train Loss 0.5268507304402134\n",
      "Epoch 2, Acc ('accuracy', 0.75984), Train Loss 0.5268507304402134\n",
      "Test Acc 0.7783678524458228\n",
      "Batch 0 Acc 0.734375 Train Loss 0.5481927543878555\n",
      "Batch 25 Acc 0.7190265486725663 Train Loss 0.5852006327074307\n",
      "Batch 50 Acc 0.7391027680559975 Train Loss 0.5627438266779862\n",
      "Batch 75 Acc 0.7544175219553486 Train Loss 0.5398808986830869\n",
      "Batch 100 Acc 0.7557505335546597 Train Loss 0.5357246518061303\n",
      "Batch 125 Acc 0.7574323892334249 Train Loss 0.5329904796939994\n",
      "Batch 150 Acc 0.7621990198167483 Train Loss 0.5270326852255705\n",
      "Batch 175 Acc 0.7651556526488258 Train Loss 0.5234504832505164\n",
      "Batch 200 Acc 0.76568 Train Loss 0.5202874721616358\n",
      "Epoch 3, Acc ('accuracy', 0.76568), Train Loss 0.5202874721616358\n",
      "Test Acc 0.7734107396111416\n",
      "Batch 0 Acc 0.8203125 Train Loss 0.4635414332151413\n",
      "Batch 25 Acc 0.7995793269230769 Train Loss 0.4614399983905829\n",
      "Batch 50 Acc 0.7847732843137255 Train Loss 0.49912776535048203\n",
      "Batch 75 Acc 0.7645345813832554 Train Loss 0.5279613622513256\n",
      "Batch 100 Acc 0.7652827204428628 Train Loss 0.519726064609419\n",
      "Batch 125 Acc 0.774061218049858 Train Loss 0.5050597366477761\n",
      "Batch 150 Acc 0.7758730495701094 Train Loss 0.5052563437192843\n",
      "Batch 175 Acc 0.7713360397755782 Train Loss 0.5099804184759374\n",
      "Batch 200 Acc 0.77332 Train Loss 0.5052812139953102\n",
      "Epoch 4, Acc ('accuracy', 0.77332), Train Loss 0.5052812139953102\n",
      "Test Acc 0.7885358800840139\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.0005, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr}, update_on_kvstore=False)\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "train(net, train_dataloader, test_dataloader, loss, trainer, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.298666Z",
     "start_time": "2019-08-06T00:55:55.973Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "50"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.299441Z",
     "start_time": "2019-08-06T00:55:55.975Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Convolutional Neural Networks (textCNN)\n",
    "\n",
    "Idea: treat text as a one-dimensional \"image\".\n",
    "\n",
    "Then we can use one-dimensional convolutional neural networks to capture associations between adjacent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This section describes a groundbreaking approach to applying\n",
    "convolutional neural networks to text analysis: textCNN :cite:`Kim.2014`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-dimensional Convolutional Layer\n",
    "\n",
    "![One-dimensional cross-correlation operation. The shaded parts are the first output element as well as the input and kernel array elements used in its calculation: $0\\times1+1\\times2=2$. ](../img/conv1d.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Before introducing the model, let us explain how a one-dimensional convolutional layer works. Like a two-dimensional convolutional layer, a one-dimensional convolutional layer uses a one-dimensional cross-correlation operation. In the one-dimensional cross-correlation operation, the convolution window starts from the leftmost side of the input array and slides on the input array from left to right successively. When the convolution window slides to a certain position, the input subarray in the window and kernel array are multiplied and summed by element to get the element at the corresponding location in the output array. As shown in Figure 12.4, the input is a one-dimensional array with a width of 7 and the width of the kernel array is 2. As we can see, the output width is $7-2+1=6$ and the first element is obtained by performing multiplication by element on the leftmost input subarray with a width of 2 and kernel array and then summing the results.\n",
    "\n",
    "\n",
    "Next, we implement one-dimensional cross-correlation in the `corr1d` function. It accepts the input array `X` and kernel array `K` and outputs the array `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.300867Z",
     "start_time": "2019-08-06T00:55:55.979Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def corr1d(X, K):\n",
    "    w = K.shape[0]\n",
    "    Y = nd.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i] = (X[i: i + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's reproduce the results of the one-dimensional cross-correlation operation seen in above Figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.302184Z",
     "start_time": "2019-08-06T00:55:55.982Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 2.  5.  8. 11. 14. 17.]\n",
       "<NDArray 6 @cpu(0)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, K = nd.array([0, 1, 2, 3, 4, 5, 6]), nd.array([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-dimensional Convolutional Layer with multiple input channels\n",
    "\n",
    "\n",
    "![One-dimensional cross-correlation operation with three input channels. The shaded parts are the first output element as well as the input and kernel array elements used in its calculation: $0\\times1+1\\times2+1\\times3+2\\times4+2\\times(-1)+3\\times(-3)=2$. ](../img/conv1d-channel.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The one-dimensional cross-correlation operation for multiple input channels is also similar to the two-dimensional cross-correlation operation for multiple input channels. On each channel, it performs the one-dimensional cross-correlation operation on the kernel and its corresponding input and adds the results of the channels to get the output. Figure 12.5 shows a one-dimensional cross-correlation operation with three input channels.\n",
    "\n",
    "Now, we reproduce the results of the one-dimensional cross-correlation operation with multi-input channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.303348Z",
     "start_time": "2019-08-06T00:55:55.985Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    return nd.add_n(*[corr1d(x, k) for x, k in zip(X, K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.316948Z",
     "start_time": "2019-08-06T00:55:55.987Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 2.  8. 14. 20. 26. 32.]\n",
       "<NDArray 6 @cpu(0)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.array([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = nd.array([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is equivalent to two-dimensional cross-correlation with a single input channel\n",
    "\n",
    "![Two-dimensional cross-correlation operation with a single input channel. The highlighted parts are the first output element and the input and kernel array elements used in its calculation: $2\\times(-1)+3\\times(-3)+1\\times3+2\\times4+0\\times1+1\\times2=2$. ](../img/conv1d-2d.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can obtain multiple output channels by applying the cross-correlation multiple times with different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Max-Over-Time Pooling Layer\n",
    "\n",
    "Similarly, we have a one-dimensional pooling layer. The max-over-time pooling layer used in TextCNN actually corresponds to a one-dimensional global maximum pooling layer. Assuming that the input contains multiple channels, and each channel consists of values on different time steps, the output of each channel will be the largest value of all time steps in the channel. Therefore, the input of the max-over-time pooling layer can have different time steps on each channel.\n",
    "\n",
    "To improve computing performance, we often combine timing examples of different lengths into a mini-batch and make the lengths of each timing example in the batch consistent by appending special characters (such as 0) to the end of shorter examples. Naturally, the added special characters have no intrinsic meaning. Because the main purpose of the max-over-time pooling layer is to capture the most important features of timing, it usually allows the model to be unaffected by the manually added characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The TextCNN Model\n",
    "\n",
    "![TextCNN design. ](../img/textcnn.svg)\n",
    "\n",
    "Kim, Yoon. \"Convolutional neural networks for sentence classification.\" EMNLP 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "TextCNN mainly uses a one-dimensional convolutional layer and max-over-time pooling layer. Suppose the input text sequence consists of $n$ words, and each word is represented by a $d$-dimension word vector. Then the input example has a width of $n$, a height of 1, and $d$ input channels. The calculation of textCNN can be mainly divided into the following steps:\n",
    "\n",
    "1. Define multiple one-dimensional convolution kernels and use them to perform convolution calculations on the inputs. Convolution kernels with different widths may capture the correlation of different numbers of adjacent words.\n",
    "2. Perform max-over-time pooling on all output channels, and then concatenate the pooling output values of these channels in a vector.\n",
    "3. The concatenated vector is transformed into the output for each category through the fully connected layer. A dropout layer can be used in this step to deal with overfitting.\n",
    "\n",
    "Figure 12.7 gives an example to illustrate the textCNN. The input here is a sentence with 11 words, with each word represented by a 6-dimensional word vector. Therefore, the input sequence has a width of 11 and 6 input channels. We assume there are two one-dimensional convolution kernels with widths of 2 and 4, and 4 and 5 output channels, respectively. Therefore, after one-dimensional convolution calculation, the width of the four output channels is $11-2+1=10$, while the width of the other five channels is $11-4+1=8$. Even though the width of each channel is different, we can still perform max-over-time pooling for each channel and concatenate the pooling outputs of the 9 channels into a 9-dimensional vector. Finally, we use a fully connected layer to transform the 9-dimensional vector into a 2-dimensional output: positive sentiment and negative sentiment predictions.\n",
    "\n",
    "Next, we will implement a textCNN model. Compared with the previous section, in addition to replacing the recurrent neural network with a one-dimensional convolutional layer, here we use two embedding layers, one with a fixed weight and another that participates in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.317545Z",
     "start_time": "2019-08-06T00:55:55.991Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TextCNN(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,\n",
    "                 **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.constant_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Dense(2)\n",
    "        self.pool = nn.GlobalMaxPool1D()\n",
    "        self.convs = nn.Sequential()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.add(nn.Conv1D(c, k, activation='relu'))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = nd.concat(\n",
    "            self.embedding(inputs), self.constant_embedding(inputs), dim=2)\n",
    "        embeddings = embeddings.transpose((0, 2, 1))\n",
    "        encoding = nd.concat(*[nd.flatten(\n",
    "            self.pool(conv(embeddings))) for conv in self.convs], dim=1)\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Create a TextCNN instance. It has 3 convolutional layers with kernel widths of 3, 4, and 5, all with 100 output channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.318140Z",
     "start_time": "2019-08-06T00:55:55.994Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "kernel_sizes, nums_channels = [3, 4, 5], [100, 100, 100]\n",
    "net = TextCNN(len(vocab), embed_size, kernel_sizes, nums_channels)\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Load Pre-trained Word Vectors\n",
    "\n",
    "As in the previous section, load pre-trained 100-dimensional GloVe word vectors and initialize the embedding layers `embedding` and `constant_embedding`. Here, the former participates in training while the latter has a fixed weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.319099Z",
     "start_time": "2019-08-06T00:55:55.997Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(idx_to_vec)\n",
    "net.constant_embedding.weight.set_data(idx_to_vec)\n",
    "net.constant_embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.320231Z",
     "start_time": "2019-08-06T00:55:55.999Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "30"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Acc 0.5703125 Train Loss 0.7208032310009003\n",
      "Batch 25 Acc 0.5955528846153846 Train Loss 0.725551961419674\n",
      "Batch 50 Acc 0.6591605392156863 Train Loss 0.6385264701995195\n",
      "Batch 75 Acc 0.6921058156623976 Train Loss 0.5888430535009033\n",
      "Batch 100 Acc 0.7154698334263171 Train Loss 0.5543311617825881\n",
      "Batch 125 Acc 0.7298317446100697 Train Loss 0.5334832864916987\n",
      "Batch 150 Acc 0.7401814300960512 Train Loss 0.5196564877220732\n",
      "Batch 175 Acc 0.7519365632305083 Train Loss 0.5022782483243976\n",
      "Batch 200 Acc 0.76068 Train Loss 0.4886269580980587\n",
      "Epoch 0, Acc ('accuracy', 0.76068), Train Loss 0.4886269580980587\n",
      "Test Acc 0.8509391899683967\n",
      "Batch 0 Acc 0.875 Train Loss 0.3213464468717575\n",
      "Batch 25 Acc 0.8625079567154679 Train Loss 0.3142663568544846\n",
      "Batch 50 Acc 0.8640807316304006 Train Loss 0.3174609286235828\n",
      "Batch 75 Acc 0.8666878778237352 Train Loss 0.31646374443938075\n",
      "Batch 100 Acc 0.8665009621552278 Train Loss 0.31580845235229127\n",
      "Batch 125 Acc 0.8671021147254737 Train Loss 0.31223812662268297\n",
      "Batch 150 Acc 0.8681883941488506 Train Loss 0.31092576335865807\n",
      "Batch 175 Acc 0.8680418972693592 Train Loss 0.30831347153963923\n",
      "Batch 200 Acc 0.86708 Train Loss 0.31082747874732836\n",
      "Epoch 1, Acc ('accuracy', 0.86708), Train Loss 0.31082747874732836\n",
      "Test Acc 0.866735487128023\n",
      "Batch 0 Acc 0.890625 Train Loss 0.21380941197276115\n",
      "Batch 25 Acc 0.9107197084725175 Train Loss 0.22252996093951738\n",
      "Batch 50 Acc 0.91455078125 Train Loss 0.21377723617479205\n",
      "Batch 75 Acc 0.9122431506849316 Train Loss 0.2144496307500001\n",
      "Batch 100 Acc 0.9121338912133892 Train Loss 0.2134369983623671\n",
      "Batch 125 Acc 0.9133914165859954 Train Loss 0.21174211865882314\n",
      "Batch 150 Acc 0.914247311827957 Train Loss 0.21275121191306817\n",
      "Batch 175 Acc 0.9148623853211009 Train Loss 0.21066773699765856\n",
      "Batch 200 Acc 0.91564 Train Loss 0.20969023220519076\n",
      "Epoch 2, Acc ('accuracy', 0.91564), Train Loss 0.20969023220519076\n",
      "Test Acc 0.8895424694272142\n",
      "Batch 0 Acc 0.9609375 Train Loss 0.09533488843590021\n",
      "Batch 25 Acc 0.9573317307692307 Train Loss 0.1242866176001441\n",
      "Batch 50 Acc 0.9546568627450981 Train Loss 0.12663036949165604\n",
      "Batch 75 Acc 0.951209341117598 Train Loss 0.13416437352517327\n",
      "Batch 100 Acc 0.9508067689885872 Train Loss 0.13406409448160245\n",
      "Batch 125 Acc 0.9520973260676721 Train Loss 0.1353339994874125\n",
      "Batch 150 Acc 0.9491435541178342 Train Loss 0.13966626179171726\n",
      "Batch 175 Acc 0.9485763825515605 Train Loss 0.13932829812091024\n",
      "Batch 200 Acc 0.94788 Train Loss 0.14031311871496374\n",
      "Epoch 3, Acc ('accuracy', 0.94788), Train Loss 0.14031311871496374\n",
      "Test Acc 0.8930601953861103\n",
      "Batch 0 Acc 0.96875 Train Loss 0.08660928439348936\n",
      "Batch 25 Acc 0.976448713975829 Train Loss 0.07803259322491403\n",
      "Batch 50 Acc 0.9759849317218647 Train Loss 0.07490550897166352\n",
      "Batch 75 Acc 0.9732434425366059 Train Loss 0.07943135024030007\n",
      "Batch 100 Acc 0.9738593155893536 Train Loss 0.07872043979252771\n",
      "Batch 125 Acc 0.9728892821031345 Train Loss 0.07915465889077279\n",
      "Batch 150 Acc 0.9724105062486761 Train Loss 0.0785623260147209\n",
      "Batch 175 Acc 0.9702934373440972 Train Loss 0.08434344070512236\n",
      "Batch 200 Acc 0.96972 Train Loss 0.08455983396178322\n",
      "Epoch 4, Acc ('accuracy', 0.96972), Train Loss 0.08455983396178322\n",
      "Test Acc 0.884732347037924\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr},\n",
    "                        update_on_kvstore=False)\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "train(net, train_dataloader, test_dataloader, loss, trainer, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Below, we use the trained model to the classify sentiments of two simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.320973Z",
     "start_time": "2019-08-06T00:55:56.002Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:01.321648Z",
     "start_time": "2019-08-06T00:55:56.004Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
