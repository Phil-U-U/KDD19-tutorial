{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gluon Implementation in Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:26.421877Z",
     "start_time": "2019-08-06T01:45:25.314866Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import d2l\n",
    "import math\n",
    "from mxnet import gluon, init, nd, autograd\n",
    "from mxnet.gluon import nn, rnn\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:28.216077Z",
     "start_time": "2019-08-06T01:45:28.210258Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "26"
    }
   },
   "outputs": [],
   "source": [
    "num_hiddens = 256\n",
    "rnn_layer = rnn.RNN(num_hiddens)\n",
    "rnn_layer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we call the `rnn_layer`'s member function `begin_state` to return hidden state list for initialization. It has an element of the shape (number of hidden layers, batch size, number of hidden units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:29.152281Z",
     "start_time": "2019-08-06T01:45:29.145794Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "37"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "state = rnn_layer.begin_state(batch_size=batch_size)\n",
    "len(state), state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN Layer in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:31.520125Z",
     "start_time": "2019-08-06T01:45:31.512113Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "38"
    }
   },
   "outputs": [],
   "source": [
    "num_steps = 1\n",
    "X = nd.random.uniform(shape=(num_steps, batch_size, len(vocab)))\n",
    "Y, state_new = rnn_layer(X, state)\n",
    "Y.shape, len(state_new), state_new[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:44.679055Z",
     "start_time": "2019-08-06T01:45:44.673249Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "39"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Block):\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dense = nn.Dense(vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = nd.one_hot(inputs.T, self.vocab_size)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # The fully connected layer will first change the shape of Y to\n",
    "        # (num_steps * batch_size, num_hiddens)\n",
    "        # Its output shape is (num_steps * batch_size, vocab_size)\n",
    "        output = self.dense(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:46.610416Z",
     "start_time": "2019-08-06T01:45:46.604190Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "41"
    }
   },
   "outputs": [],
   "source": [
    "def predict(prefix, num_predicts, model, vocab, ctx):\n",
    "    state = model.begin_state(batch_size=1, ctx=ctx)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: nd.array([outputs[-1]], ctx=ctx).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # Warmup state with prefix\n",
    "        _, state = model(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_predicts):  # Predict num_predicts steps\n",
    "        Y, state = model(get_input(), state)\n",
    "        outputs.append(int(Y.argmax(axis=1).reshape(1).asscalar()))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Prediction with Garbage Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:49.717280Z",
     "start_time": "2019-08-06T01:45:49.690189Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "42"
    }
   },
   "outputs": [],
   "source": [
    "ctx = d2l.try_gpu()\n",
    "\n",
    "model = RNNModel(rnn_layer, len(vocab))\n",
    "model.initialize(force_reinit=True, ctx=ctx)\n",
    "predict('time traveller', 10, model, vocab, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We need to clip gradients to avoid divergence in optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:45:52.562407Z",
     "start_time": "2019-08-06T01:45:52.557352Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(model, theta):\n",
    "    if isinstance(model, gluon.Block):\n",
    "        params = [p.data() for p in model.collect_params().values()]\n",
    "    else:\n",
    "        params = model.params\n",
    "    norm = math.sqrt(sum((p.grad ** 2).sum().asscalar() for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:46:02.061007Z",
     "start_time": "2019-08-06T01:46:02.053478Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iter, loss, updater, ctx, use_random_iter):\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # loss_sum, num_examples\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # Initialize state when either it's the first iteration or\n",
    "            # using random sampling.\n",
    "            state = model.begin_state(batch_size=X.shape[0], ctx=ctx)\n",
    "        else:\n",
    "            for s in state: s.detach()\n",
    "        y = Y.T.reshape((-1,))\n",
    "        X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            py, state = model(X, state)\n",
    "            l = loss(py, y).mean()\n",
    "        l.backward()\n",
    "        grad_clipping(model, 1)\n",
    "        updater(batch_size=1)  # Since used mean already.\n",
    "        metric.add(l.asscalar() * y.size, y.size)\n",
    "    return math.exp(metric[0]/metric[1]), metric[1]/timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:46:14.960065Z",
     "start_time": "2019-08-06T01:46:14.951672Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "18"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_iter, vocab, lr, num_epochs, ctx,\n",
    "              use_random_iter=False):\n",
    "    # Initialize\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[1, num_epochs])\n",
    "    if isinstance(model, gluon.Block):\n",
    "        model.initialize(ctx=ctx, force_reinit=True, init=init.Normal(0.01))\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "        updater = lambda batch_size : trainer.step(batch_size)\n",
    "    else:\n",
    "        updater = lambda batch_size : d2l.sgd(model.params, lr, batch_size)\n",
    "\n",
    "    prediction = lambda prefix: predict(prefix, 50, model, vocab, ctx)\n",
    "    # Train and check the progress.\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch(\n",
    "            model, train_iter, loss, updater, ctx, use_random_iter)\n",
    "        if epoch % 10 == 0:\n",
    "            print(prediction('time traveller'))\n",
    "            animator.add(epoch+1, [ppl])\n",
    "    print('Perplexity %.1f, %d tokens/sec on %s' % (ppl, speed, ctx))\n",
    "    print(prediction('time traveller'))\n",
    "    print(prediction('traveller'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train the model using the same hyper-parameters as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:47:18.185155Z",
     "start_time": "2019-08-06T01:46:24.265593Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train(model, train_iter, vocab, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
