{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT Pre-training and Fine-tuning\n",
    "\n",
    "In this notebook, you will understand how to implement the BERT model for pre-training, and to fine-tune a pre-trained BERT model for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preparation\n",
    "\n",
    "First, let's import necessary modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note that utils.py includes some Blocks defined in the previous transformer notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:35.801121Z",
     "start_time": "2019-07-25T15:25:34.373063Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "\n",
    "import d2l\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from utils import PositionalEncoding, MultiHeadAttention \n",
    "from utils import AddNorm, PositionWiseFFN, EncoderBlock\n",
    "from utils import train_loop, predict_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoder\n",
    "\n",
    "Different from the transformer encoder, the BERT encoder has an additional embedding for segment information.\n",
    "\n",
    "<img src=\"transformer-bert.png\" alt=\"architecture\" width=\"450\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Segment Embedding\n",
    "\n",
    "![segment embedding](bert-embed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Similar to the Transformer encoder defined in the previous section, the BERT encoder has embeddings for words and positions. The `EncoderBlock` contains position-wise feed-forward network and self-attention blocks to encode inputs. For BERT, the newly added segment embedding captures the segment information of the input sentence pairs, used for the next sentence prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BERT Encoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:35.808300Z",
     "start_time": "2019-07-25T15:25:35.803080Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class BERTEncoder(gluon.nn.Block):\n",
    "    def __init__(self, vocab_size, units, hidden_size,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(BERTEncoder, self).__init__(**kwargs)\n",
    "        # segment_embed for segment information\n",
    "        self.segment_embed = gluon.nn.Embedding(2, units)\n",
    "        self.word_embed = gluon.nn.Embedding(vocab_size, units)\n",
    "        self.pos_encoding = PositionalEncoding(units, dropout)\n",
    "        self.blks = gluon.nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add(EncoderBlock(units, hidden_size, num_heads, dropout))\n",
    "\n",
    "    def forward(self, words, segments, mask, *args):\n",
    "        X = self.word_embed(words) + self.segment_embed(segments)\n",
    "        X = self.pos_encoding(X)\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, mask)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:18:53.941415Z",
     "start_time": "2019-07-25T15:18:53.937699Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using BERT Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now let's test the BERTEncoder with a data batch of 2 sentence pairs, each with 8 words. Random integers are used to represent words for demonstration purpose. For segment information, we use 0 to indicate the word comes from the first sentence, 1 to indicate the second setence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:36.052797Z",
     "start_time": "2019-07-25T15:25:35.810765Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8, 768)\n"
     ]
    }
   ],
   "source": [
    "encoder = BERTEncoder(vocab_size=30000, units=768, hidden_size=3072,\n",
    "                      num_heads=12, num_layers=12, dropout=0.1)\n",
    "encoder.initialize()\n",
    "\n",
    "num_samples, num_words = 2, 8\n",
    "# random words for testing\n",
    "words = nd.random.randint(low=0, high=30000, shape=(num_samples, num_words))\n",
    "# the corresponding segment information for each word\n",
    "segments = nd.array([[0,0,0,0,1,1,1,1],[0,0,0,1,1,1,1,1]])\n",
    "\n",
    "encodings = encoder(words, segments, None)\n",
    "print(encodings.shape) # (batch_size, num_words, units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next Sentence Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let us take a look at the first pre-training task: next sentence prediction. For this task, the encoding of the first token (the \"[CLS]\" token) is passed to a feed-forward network to make prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:36.060009Z",
     "start_time": "2019-07-25T15:25:36.054975Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class NSClassifier(gluon.nn.Block):\n",
    "    def __init__(self, units=768, **kwargs):\n",
    "        super(NSClassifier, self).__init__(**kwargs)\n",
    "        self.classifier = gluon.nn.Sequential()\n",
    "        self.classifier.add(gluon.nn.Dense(units=units, flatten=False, activation='tanh'))\n",
    "        # binary classification layer\n",
    "        self.classifier.add(gluon.nn.Dense(units=1, flatten=False))\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        X = X[:, 0, :]  # get the encoding of the first token\n",
    "        pred = self.classifier(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Next Sentence Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Since next sentence prediction is a binary classification problem, we can use `SigmoidBinaryCrossEntropyLoss` as the loss function. In the following code block, we pass the encoding results to the `NSClassifier` to get the next sentence prediction. We use 1 as the label for true next sentence, and 0 otherwise. The prediction result and the label are then passed to the loss function for loss evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:36.095042Z",
     "start_time": "2019-07-25T15:25:36.062066Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "ns_classifier = NSClassifier()\n",
    "ns_classifier.initialize()\n",
    "\n",
    "ns_pred = ns_classifier(encodings) # (batch_size, 1)\n",
    "ns_label = nd.array([0, 1]) # 1 for true next setence, 0 otherwise\n",
    "ns_loss_fn = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "ns_loss = ns_loss_fn(ns_pred, ns_label).mean()\n",
    "print(ns_pred.shape, ns_loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Masked Language Model Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Masked language modeling is one of the two pre-training task, where random positions are masked and the model needs to reconstruct the masked words. In the masked language model decoder, we first use `gather_nd` to pick the dense vectors representing words at masked position. Then a feed-forward network is applied on them, followed by a fully-connected layer to predict the unnormalized score for all words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:36.104888Z",
     "start_time": "2019-07-25T15:25:36.098073Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MLMDecoder(gluon.nn.Block):\n",
    "    def __init__(self, vocab_size, units, **kwargs):\n",
    "        super(MLMDecoder, self).__init__(**kwargs)\n",
    "        self.decoder = gluon.nn.Sequential()\n",
    "        self.decoder.add(gluon.nn.Dense(units, flatten=False))\n",
    "        # Gaussian Error Linear Units as the activation function [4]\n",
    "        self.decoder.add(gluon.nn.GELU())\n",
    "        self.decoder.add(gluon.nn.LayerNorm())\n",
    "        # classification layer for `vocab_size` classes\n",
    "        self.decoder.add(gluon.nn.Dense(vocab_size, flatten=False))\n",
    "\n",
    "    def forward(self, X, masked_positions, *args):\n",
    "         # gather encodings at mask positions\n",
    "        X = nd.gather_nd(X, masked_positions)\n",
    "        pred = self.decoder(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Masked Language Model Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In the following code block, we pass the encoding results to the `MLMDecoder` to get the masked language model prediction. We generate some random word indices as the label for demonstration purpose. For multi-class classification, we can use `SoftmaxCrossEntropyLoss` as the loss function. The prediction result and the label are then passed to the loss function for loss evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:36.131624Z",
     "start_time": "2019-07-25T15:25:36.107346Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30000) (1,)\n"
     ]
    }
   ],
   "source": [
    "decoder = MLMDecoder(vocab_size=30000, units=768)\n",
    "decoder.initialize()\n",
    "\n",
    "mlm_positions = nd.array([[0,1],[4,8]])\n",
    "mlm_label = nd.array([100, 200])\n",
    "mlm_pred = decoder(encodings, mlm_positions) # (batch_size, vocab_size)\n",
    "mlm_loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "mlm_loss = mlm_loss_fn(mlm_pred, mlm_label).mean()\n",
    "print(mlm_pred.shape, mlm_loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BERT Fine-tuning (Sentiment Analysis)\n",
    "\n",
    "In this section, we fine-tune the BERT Base model for sentiment analysis on the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### BERT for Sentence Classification\n",
    "\n",
    "Let's first take\n",
    "a look at the BERT model\n",
    "architecture for single sentence classification below:\n",
    "<div style=\"width:\n",
    "500px;\">![bert-sa](bert-sa.png)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here the model takes a sentences and pools the representation of the first token in the sequence.\n",
    "Note that the original BERT model was trained for a masked language model and next-sentence prediction tasks, which includes layers for language model decoding and\n",
    "classification. These layers will not be used for fine-tuning sentence classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get Pre-train BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can load the pre-trained BERT fairly easily using the model API in GluonNLP, which returns the vocabulary along with the model. We include the pooler layer of the pre-trained model by setting `use_pooler` to `True`.\n",
    "The list of pre-trained BERT models available in GluonNLP can be found [here](../../model_zoo/bert/index.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:40.981689Z",
     "start_time": "2019-07-25T15:25:36.138029Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ctx = mx.gpu(0) if mx.test_utils.list_gpus() else mx.cpu()\n",
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                            dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                            pretrained=True, ctx=ctx,\n",
    "                                            use_decoder=False, use_classifier=False)\n",
    "print(bert_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model for Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T05:49:04.134949Z",
     "start_time": "2019-07-25T05:49:04.130714Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now that we have loaded the BERT model, we only need to attach an additional layer for classification.\n",
    "The `BERTClassifier` class uses a BERT base model to encode sentence representation, followed by a `nn.Dense` layer for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:40.986982Z",
     "start_time": "2019-07-25T15:25:40.983647Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(gluon.nn.Block):\n",
    "    def __init__(self, bert, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        # extra layer used for classification\n",
    "        self.classifier = gluon.nn.Dense(num_classes)\n",
    "\n",
    "    def forward(self, inputs, segment_types, seq_len):\n",
    "        seq_encoding, cls_encoding = self.bert(inputs, segment_types, seq_len)\n",
    "        return self.classifier(cls_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:21:33.159727Z",
     "start_time": "2019-07-25T15:21:33.157231Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Initialization and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We only need to initialize the classification layer. The encoding layers are already initialized with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:40.997119Z",
     "start_time": "2019-07-25T15:25:40.988725Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = BERTClassifier(bert_base, 2)\n",
    "net.classifier.initialize(ctx=ctx)\n",
    "loss_fn = gluon.loss.SoftmaxCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing for BERT\n",
    "\n",
    "For this tutorial, we need to do a bit of preprocessing before feeding our data introduced\n",
    "the BERT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the dataset\n",
    "\n",
    "We again use the IMDB dataset, but for this time, downloading using the GluonNLP data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.306370Z",
     "start_time": "2019-07-25T15:25:40.998884Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_raw = nlp.data.IMDB('train')\n",
    "test_dataset_raw = nlp.data.IMDB('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then use the transform API to transform the raw scores to positive labels and negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.311346Z",
     "start_time": "2019-07-25T15:25:41.308237Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def transform_label(data):\n",
    "    # Transform label into position / negative\n",
    "    text, label = data\n",
    "    return text, 1 if label >= 5 else 0\n",
    "train_dataset = train_dataset_raw.transform(transform_label)\n",
    "test_dataset = test_dataset_raw.transform(transform_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BERT-specific Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To use the pre-trained BERT model, we need to tokenize the data in the same\n",
    "way it was trained. We need to perform the following transformations:\n",
    "- tokenize the inputs into word pieces\n",
    "- insert [CLS] at the beginning of a sentence\n",
    "- insert [SEP] at the end of a sentence\n",
    "- generate segment ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BERT Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's take a look at the vocabulary previously downloaded from the `model.get_model` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.317556Z",
     "start_time": "2019-07-25T15:25:41.313058Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "index for [CLS] =  2\n",
      "index for [SEP] =  3\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)\n",
    "print('index for [CLS] = ', vocabulary['[CLS]'])\n",
    "print('index for [SEP] = ', vocabulary['[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tokenization for BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can perform tokenization with `data.BERTTokenizer` API. The vocabulary from pre-trained model is used to construct the tokenizer. Let's take a look at the tokenization result of a short sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.323502Z",
     "start_time": "2019-07-25T15:25:41.319285Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "You'd better choose Paul Verhoeven's even if you have watched it.\n",
      "\n",
      "tokenized text:\n",
      "you ' d better choose paul ve ##rh ##oe ##ven ' s even if you have watched it .\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
    "text, label = train_dataset[16854]\n",
    "print('original text:')\n",
    "print(text)\n",
    "print('\\ntokenized text:')\n",
    "print(' '.join(tokenizer(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To process sentences with BERT-style '[CLS]', '[SEP]' tokens, you can use `data.BERTSentenceTransform` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.328631Z",
     "start_time": "2019-07-25T15:25:41.325176Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def transform_fn(text, label):\n",
    "    max_len = 128\n",
    "    transform = nlp.data.BERTSentenceTransform(tokenizer, max_len,\n",
    "                                               pad=False, pair=False)\n",
    "    data, length, segment_type = transform([text])\n",
    "    data = data.astype('float32')\n",
    "    length = length.astype('float32')\n",
    "    segment_type = segment_type.astype('float32')\n",
    "    return data, length, segment_type, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.348682Z",
     "start_time": "2019-07-25T15:25:41.330351Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words =  [    2 22953  2213  4381  2152  2003  1037  9476  4038  1012  2009  2743\n",
      "  2012  1996  2168  2051  2004  2070  2060  3454  2055  2082  2166  1010\n",
      "  2107  2004  1000  5089  1000  1012  2026  3486  2086  1999  1996  4252\n",
      "  9518  2599  2033  2000  2903  2008 22953  2213  4381  2152  1005  1055\n",
      " 18312  2003  2172  3553  2000  4507  2084  2003  1000  5089  1000  1012\n",
      "  1996 25740  2000  5788 13732  1010  1996 12369  3993  2493  2040  2064\n",
      "  2156  2157  2083  2037 17203  5089  1005 13433  8737  1010  1996  9004\n",
      " 10196  4757  1997  1996  2878  3663  1010  2035 10825  2033  1997  1996\n",
      "  2816  1045  2354  1998  2037  2493  1012  2043  1045  2387  1996  2792\n",
      "  1999  2029  1037  3076  8385  2699  2000  6402  2091  1996  2082  1010\n",
      "  1045  3202  7383  1012  1012  1012  1012     3]\n",
      "segments =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "data, length, segment_type, label = transform_fn(*train_dataset[0])\n",
    "print('words = ', data.astype('int32'))\n",
    "print('segments = ', segment_type.astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batchify and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.354982Z",
     "start_time": "2019-07-25T15:25:41.350583Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "padding_id = vocabulary[vocabulary.padding_token]\n",
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "        # words: the first dimension is the batch dimension\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=padding_id),\n",
    "        # valid length\n",
    "        nlp.data.batchify.Stack(),\n",
    "        # segment type : the first dimension is the batch dimension\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=padding_id),\n",
    "        # label\n",
    "        nlp.data.batchify.Stack(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:25:41.361804Z",
     "start_time": "2019-07-25T15:25:41.356909Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data = gluon.data.DataLoader(train_dataset.transform(transform_fn, lazy=False),\n",
    "                                   batchify_fn=batchify_fn, shuffle=True,\n",
    "                                   batch_size=batch_size)\n",
    "test_data = gluon.data.DataLoader(test_dataset.transform(transform_fn, lazy=False), \n",
    "                                  batchify_fn=batchify_fn,\n",
    "                                  shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "Now we have all the pieces to put together, and we can finally start fine-tuning the\n",
    "model with a few epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:49:52.786787Z",
     "start_time": "2019-07-25T15:25:41.363588Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Accuracy 0.375 Loss 0.8368113040924072\n",
      "Batch 50 Accuracy 0.7181372549019608 Loss 0.5542773452459597\n",
      "Batch 100 Accuracy 0.7462871287128713 Loss 0.5264608930833269\n",
      "Batch 150 Accuracy 0.7661423841059603 Loss 0.4933283218484841\n",
      "Batch 200 Accuracy 0.7761194029850746 Loss 0.4740876155113106\n",
      "Batch 250 Accuracy 0.7883466135458167 Loss 0.4612688467322118\n",
      "Batch 300 Accuracy 0.7929817275747508 Loss 0.451099484465843\n",
      "Batch 350 Accuracy 0.7988782051282052 Loss 0.44313453609107906\n",
      "Batch 400 Accuracy 0.8026028678304239 Loss 0.4367703178576995\n",
      "Batch 450 Accuracy 0.8084118625277162 Loss 0.42513361421234064\n",
      "Batch 500 Accuracy 0.812687125748503 Loss 0.41579414413360777\n",
      "Batch 550 Accuracy 0.8164133393829401 Loss 0.4082401504101208\n",
      "Batch 600 Accuracy 0.8214434276206323 Loss 0.39868346863300747\n",
      "Batch 650 Accuracy 0.8254608294930875 Loss 0.3916504328152002\n",
      "Batch 700 Accuracy 0.827478601997147 Loss 0.3877677101211439\n",
      "Batch 750 Accuracy 0.8303928095872171 Loss 0.3820333061777006\n",
      "Epoch 0, Accuracy ('accuracy', 0.83104), Loss 0.38076540271339515\n",
      "Test Accuracy 0.8783567774936062\n",
      "Batch 0 Accuracy 0.96875 Loss 0.16268713772296906\n",
      "Batch 50 Accuracy 0.9411764705882353 Loss 0.17988186256558286\n",
      "Batch 100 Accuracy 0.9359529702970297 Loss 0.18758212929905052\n",
      "Batch 150 Accuracy 0.9308774834437086 Loss 0.19373274796845896\n",
      "Batch 200 Accuracy 0.9314365671641791 Loss 0.19391201266008823\n",
      "Batch 250 Accuracy 0.9300298804780877 Loss 0.19476143582408648\n",
      "Batch 300 Accuracy 0.9312707641196013 Loss 0.191128372750013\n",
      "Batch 350 Accuracy 0.9327813390313391 Loss 0.1849390665690104\n",
      "Batch 400 Accuracy 0.9325124688279302 Loss 0.18601635863953397\n",
      "Batch 450 Accuracy 0.9314024390243902 Loss 0.18852108703748613\n",
      "Batch 500 Accuracy 0.9310129740518962 Loss 0.1881653867557853\n",
      "Batch 550 Accuracy 0.9317150635208712 Loss 0.18704302557583513\n",
      "Batch 600 Accuracy 0.9321443427620633 Loss 0.18616512254153234\n",
      "Batch 650 Accuracy 0.9325556835637481 Loss 0.18534510036767354\n",
      "Batch 700 Accuracy 0.9331312410841655 Loss 0.18411370248835368\n",
      "Batch 750 Accuracy 0.9328811584553928 Loss 0.18411189865335803\n",
      "Epoch 1, Accuracy ('accuracy', 0.93304), Loss 0.18300435488181346\n",
      "Test Accuracy 0.8823929028132992\n",
      "Batch 0 Accuracy 1.0 Loss 0.025675596669316292\n",
      "Batch 50 Accuracy 0.9761029411764706 Loss 0.08135535670261757\n",
      "Batch 100 Accuracy 0.9730816831683168 Loss 0.09293213457164198\n",
      "Batch 150 Accuracy 0.9743377483443708 Loss 0.09843223142308115\n",
      "Batch 200 Accuracy 0.9740360696517413 Loss 0.10060498251843808\n",
      "Batch 250 Accuracy 0.9737300796812749 Loss 0.10394459606641793\n",
      "Batch 300 Accuracy 0.9748754152823921 Loss 0.09946941616527266\n",
      "Batch 350 Accuracy 0.9740028490028491 Loss 0.10529006784118479\n",
      "Batch 400 Accuracy 0.9737375311720698 Loss 0.10672061758445682\n",
      "Batch 450 Accuracy 0.9742239467849224 Loss 0.10561444436895874\n",
      "Batch 500 Accuracy 0.9742390219560878 Loss 0.10643038873425024\n",
      "Batch 550 Accuracy 0.9747617967332124 Loss 0.10436489707545231\n",
      "Batch 600 Accuracy 0.9748336106489185 Loss 0.10615293912205244\n",
      "Batch 650 Accuracy 0.9746543778801844 Loss 0.10829230570756529\n",
      "Batch 700 Accuracy 0.9748127674750356 Loss 0.10835600239404088\n",
      "Batch 750 Accuracy 0.9750749001331558 Loss 0.10835696854064372\n",
      "Epoch 2, Accuracy ('accuracy', 0.97512), Loss 0.10716298291140505\n",
      "Test Accuracy 0.8816735933503836\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "lr = 0.00005\n",
    "train_loop(net, train_data, test_data, num_epoch, lr, ctx, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T15:49:52.821670Z",
     "start_time": "2019-07-25T15:49:52.788762Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, ctx, vocabulary, tokenizer, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we showed how to fine-tune sentiment analysis model with pre-trained BERT parameters. In GluonNLP, this can be done with such few, simple steps. All we did was apply a BERT-style data transformation to pre-process the data, automatically download the pre-trained model, and feed the transformed data into the model, all within 50 lines of code!\n",
    "\n",
    "For more fine-tuning scripts, visit the [BERT model zoo webpage](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html).\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Devlin, Jacob, et al. \"Bert:\n",
    "Pre-training of deep\n",
    "bidirectional transformers for language understanding.\"\n",
    "arXiv preprint\n",
    "arXiv:1810.04805 (2018).\n",
    "\n",
    "[2] Dolan, William B., and Chris\n",
    "Brockett.\n",
    "\"Automatically constructing a corpus of sentential paraphrases.\"\n",
    "Proceedings of\n",
    "the Third International Workshop on Paraphrasing (IWP2005). 2005.\n",
    "\n",
    "[3] Peters,\n",
    "Matthew E., et al. \"Deep contextualized word representations.\" arXiv\n",
    "preprint\n",
    "arXiv:1802.05365 (2018).\n",
    "\n",
    "[4] Hendrycks, Dan, and Kevin Gimpel. \"Gaussian error linear units (gelus).\" arXiv preprint arXiv:1606.08415 (2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For fine-tuning, we only need to initialize the last classifier layer from scratch. The other layers are already initialized from the pre-trained model weights."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
